[[lifecycle]]
== Simple application lifecycle

****
IMPORTANT: *TODO*

Describe the scripts within an S2I build (compile, assemble, execute)

****

[[lifecycle-s2i]]
=== Deploying an application using S2I

In the Catalog of your sandbox project:

* Filter (top tab bar) *Languages*
* Select *JavaScript*
* Choose *Node.js*

image::screenshot_catalog_filter_js.png[Node application]

You will now go though a wizzard to gather all data needed for this S2I build config:

****
IMPORTANT: *TODO*

Explain the nature of the wizards

****

* Click btn:[Next] on first page of Wizard.

****
IMPORTANT: *TODO*

Explain the parameter fields as pertains to templates

****

* Select node image version *10*
* Enter name as `nodetest`
* Enter the following url as the github repo https://github.com/utherp0/ocpnode[https://github.com/utherp0/ocpnode]

Click btn:[Create], then btn:[Close] to close the wizard

image::screenshot_s2i_wizard.png[S2I Wizard]

Now go back to the menu:Overview[] page.

****
IMPORTANT: *TODO*

Explain the behaviour that is happening, the creation of the objects from the template, 
the build-config being used by the build, the build delivering the image into the registry, 
the deployment-config waiting on the image arrival, the default single Pod deployment, the creation of the route

****
[[lifecycle-running]]
=== The running application

When in the Overview page, you will see all running applications. Expand the `nodetest` application we just deployed.
You will see an overview of the running application:

* Information on the running container
* Number of pods and the status (a.k.a kbd:[Pod ring]) of the pods
* Networking information including internal port mapping and external routes
* Build history and information

image::screenshot_app_overview.png[Application Overview]

To see the application in action, click on the link in the external route.
This will open the basic node.js application:

image::screenshot_node_app.png[Node.js Application]

[[lifecycle-application-services]]
==== Application Services

Using the menu on the left go to the menu:Applications[Services] page.

image::screenshot_app_services.png[Application Services]

****
IMPORTANT: *TODO*

Explain the nature of the single service endpoint for the application - note the cluster IP address

****

NOTE: More info here: 
https://docs.openshift.com/container-platform/3.11/architecture/core_concepts/pods_and_services.html#services[https://docs.openshift.com/container-platform/3.11/architecture/core_concepts/pods_and_services.html#services]

Go back to the menu:Overview[] page.

[[lifecycle-application-pods]]
==== Application Pods

Click on the kbd:[Pod ring], or alternatively use the menu menu:Applications[Pods > nodetest-****]

image::screenshot_app_pod.png[Application Pod]

TIP: See the differing IP address for the Pod compared to the cluster IP

Go back to the menu:Overview[] page.

[[lifecycle-application-scaling]]
==== Application Scaling

Let's pretend that this app is suddenly getting many requests from many users (so there is a load increase on the app).
So we need to scale the application to 3 instances.

Click the menu:Up arrow[] (^) until there are 3 replicas.

image::screenshot_scaling_up.png[Application Scaling]

****
IMPORTANT: *TODO*

Explain the blue, gray, dark blue, red colour schemes for the Pod behaviors

****

Click on the kbd:[Pod ring], or alternatively use the menu menu:Applications[Deployments > nodetest > #1 (latest)].

Scroll down to where the Pods are listed:

image::screenshot_app_pods_3.png[Pod listing]

TIP: See the difference in age between the initial pod and the 2 recent scaled pods.

Select on of the recent (younger) pods.

TIP: Note the IP difference compared to the initial pod.

****
IMPORTANT: *TODO*

Explain the load-balancing of Pod IP endpoints from the singular cluster IP and how that abstracts from the Route.

****

[[lifecycle-application-route]]
==== Application Route

Using the menu on the left go to the menu:Applications[Routes] page.

image::screenshot_app_routes.png[Application Routes]

TIP: Note the mapping of the fully qualified domain name to the cluster IP via the service name

Select the nodetest link in the service column. 

image::screenshot_route_service.png[Route service]

TIP: Note that the route maps to the cluster IP

[[lifecycle-application-cli]]
==== Application from CLI

Now let's go to the console (either using `localhost` or `oconline` as explained in the <<setup-cli>> section)

Make sure you are still logged in:

[source,shell]
----
oc whoami
----

(if not, log in again as explained in the <<setup-login>> section)

Make sure we are using our sandbox project:

[source,shell]
----
oc project sandbox-userX
----

This will print: 

[source,shell,subs=attributes+]
----
Now using project "sandbox-userX" on server "{webConsoleUrl}:443".
----

You can find all `objects` that you can interact with in this namespace/project:

[source,shell]
----
oc get all
----

Get all `pods`:

[source,shell]
----
oc get pods -o wide
----

This will output something similar to this:

[source,shell]
----
NAME               READY     STATUS      RESTARTS   AGE       IP          NODE                      NOMINATED NODE
nodetest-1-2g2dz   1/1       Running     0          23h       10.1.2.67   node1.jhb-94d8.internal   <none>
nodetest-1-54fw7   1/1       Running     0          3h        10.1.2.74   node1.jhb-94d8.internal   <none>
nodetest-1-6xw6g   1/1       Running     0          3h        10.1.2.75   node1.jhb-94d8.internal   <none>
nodetest-1-build   0/1       Completed   0          23h       10.1.2.65   node1.jhb-94d8.internal   <none>
----

TIP: Note the pod used to build the project is there, just inactive. +
Also note the differing IPs for the individual Pods and the NODE information.

In the Web Console, make sure you are on the btn:[Overview] page, then do the following in CLI while watching the page:

[source,shell]
----
oc delete pod nodetest-****
----
(Replace ******** with once of the running pods)

image::screenshot_deleting_pod.png[Deleting a pod]

****
IMPORTANT: *TODO*

Explain the nature of Liveness (kill/restart) and Readiness (if not ready Pod IP is removed from the round-robin HAProxy)

****

[[lifecycle-health-checks]]
==== Health Checks

In the Web Console, go to menu:Applications[Deployments > nodetest > Configuration].

Under Template, click `Add Health Checks`:

image::screenshot_add_health.png[Adding Health Checks]

TIP:
Click on the `Learn More` link or 
here: https://docs.openshift.com/container-platform/3.11/dev_guide/application_health.html[https://docs.openshift.com/container-platform/3.11/dev_guide/application_health.html]
to read more about Health probes

****
IMPORTANT: *TODO*

Explain the concepts of the readiness and health probes

****

[[lifecycle-rolling-recreate]]
==== Rolling and Recreate updates

